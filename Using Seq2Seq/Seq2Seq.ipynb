{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "84cd8a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811cc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.clear()\n",
    "        \n",
    "    def build_vocab(self,tokenized_text,max_len=None,unk_token=\"<UNK>\", others=None):\n",
    "        \n",
    "        if self.__vocab_built:\n",
    "            raise Exception(\"Vocab already built. Please use the .clear() methode if you want to rebuild!\")\n",
    "        \n",
    "        self.clear()\n",
    "        self.__word_to_index[unk_token]=self.__special_cnt\n",
    "        self.__index_to_word[self.__special_cnt] = unk_token\n",
    "        self.__special_cnt+=1\n",
    "        \n",
    "        if others:\n",
    "            for token in others:\n",
    "                if token not in self.__word_to_index:\n",
    "                    self.__word_to_index[token] = self.__special_cnt\n",
    "                    self.__index_to_word[self.__special_cnt] = token\n",
    "                    self.__special_cnt += 1\n",
    "        \n",
    "        \n",
    "        tokens =  list(np.concatenate(tokenized_text).flatten())\n",
    "        tokens =  sorted(tokens)\n",
    "        word_to_count={}\n",
    "        \n",
    "        if max_len:\n",
    "            if(max_len<self.__special_cnt):\n",
    "                raise Exception('Max length must be larger than number of special tokens')\n",
    "                \n",
    "            self.max_len = max_len \n",
    "            \n",
    "            for token in tokens:\n",
    "                if token in word_to_count:\n",
    "                    word_to_count[token] += 1\n",
    "                else:\n",
    "                     word_to_count[token] = 1\n",
    "        \n",
    "        \n",
    "        tokens = list(set(tokens))\n",
    "            \n",
    "        if max_len:\n",
    "            current_length = self.__special_cnt + len(tokens)\n",
    "            if current_length > max_len:\n",
    "                sorted_count = dict(sorted(word_to_count.items(), key = lambda x: x[1]))\n",
    "                    \n",
    "                for i, (word,count) in enumerate(sorted_count.items()):\n",
    "                    if i >= current_length - max_len:\n",
    "                        break\n",
    "                    tokens.remove(word)\n",
    "                    \n",
    "                    \n",
    "        for token in tokens:\n",
    "            self.__word_to_index[token] = self.__special_cnt + self.__len\n",
    "            self.__index_to_word[self.__special_cnt + self.__len] = token\n",
    "            self.__len +=1\n",
    "    \n",
    "        self.__vocab_built=True\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.__len+self.__special_cnt\n",
    "        \n",
    "    def clear(self):\n",
    "        self.__special_cnt=0\n",
    "        self.__len =0\n",
    "        self.__word_to_index={}\n",
    "        self.__index_to_word={}\n",
    "        self.max_len=0\n",
    "        self.__vocab_built = False\n",
    "                \n",
    "    def tokens_to_bow(self,tokenized_sentence):\n",
    "        if not self.__vocab_built:\n",
    "            raise Exception(\"Vocabulary not built yet!\")\n",
    "\n",
    "        out =[]\n",
    "        for token in tokenized_sentence:\n",
    "            out.append(self.__word_to_index[token] if token in self.__word_to_index else 0)\n",
    "        return out\n",
    "    \n",
    "    def bow_to_tokens(self, bow):\n",
    "        if not self.__vocab_built:\n",
    "            raise Exception(\"Vocabulary not built yet!\")\n",
    "        \n",
    "        out=[]\n",
    "        for idx in bow:\n",
    "            if idx not in self.__index_to_word:\n",
    "                raise Exception('Invalid index')\n",
    "            out.append(self.__index_to_word[idx])\n",
    "        return out\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        if not self.__vocab_built:\n",
    "            raise Exception(\"Vocabulary not built yet!\")\n",
    "            \n",
    "        return self.__word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d87c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_ger = spacy.load('de_core_news_sm')\n",
    "spacy_eng = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d60f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_en(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text.lower())]\n",
    "def tokenizer_de(text):\n",
    "    return [tok.text for tok in spacy_ger.tokenizer(text.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9c25ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = Multi30k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "494ea534",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train = []\n",
    "de_train = []\n",
    "\n",
    "for (de,en) in train_data:\n",
    "    de_train.append(tokenizer_de(de))\n",
    "    en_train.append(tokenizer_en(en))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c747aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_vocab = Vocab()\n",
    "english_vocab.build_vocab(en_train, max_len=10000, unk_token='<UNK>', others=['<SOS>','<EOS>','<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8191f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_vocab = Vocab()\n",
    "german_vocab.build_vocab(de_train,max_len=10000, unk_token='<UNK>', others=['<SOS>','<EOS>','<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cee689a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.de = de_train\n",
    "        self.en = en_train\n",
    "        self.len = len(de_train)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return self.de[idx] , self.en[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "train_dataset =  Train_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da178e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    out_de, out_en = [],[] \n",
    "    \n",
    "    \n",
    "    for de, en in batch:\n",
    "        out_de.append(german_vocab.tokens_to_bow(['<SOS>']+de+['<EOS>']))\n",
    "        out_en.append(english_vocab.tokens_to_bow(['<SOS>']+en+['<EOS>']))\n",
    "    \n",
    "    \n",
    "    \n",
    "    de_pad = german_vocab.tokens_to_bow(['<PAD>'])\n",
    "    en_pad = english_vocab.tokens_to_bow(['<PAD>'])\n",
    "    \n",
    "    \n",
    "    max_len_de = len(max(out_de,key=len))\n",
    "    max_len_en = len(max(out_en,key=len))\n",
    "    \n",
    "    for i in range(len(out_de)):\n",
    "        out_de[i].extend(de_pad*(max_len_de - len(out_de[i])))\n",
    "    \n",
    "    for i in range(len(out_en)):\n",
    "        out_en[i].extend(en_pad*(max_len_en - len(out_en[i])))\n",
    "        \n",
    "    return torch.tensor(out_de,dtype=torch.int64),torch.tensor(out_en,dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "751c70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size , embedding_size, hidden_size, num_layers, dropout_p):\n",
    "        super(Encoder,self).__init__()\n",
    "    \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.dropout=nn.Dropout(p=dropout_p)\n",
    "        self.embedding=nn.Embedding(input_size,embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,hidden_size,num_layers=num_layers, dropout=dropout_p, batch_first=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        \n",
    "        out = self.dropout(self.embedding(x))\n",
    "        \n",
    "        out, (hidden,cell) = self.lstm(out)\n",
    "        \n",
    "        return hidden,cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20a369e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout_p):\n",
    "        super(Decoder,self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.dropout=nn.Dropout(p=dropout_p)\n",
    "        self.embedding=nn.Embedding(input_size,embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,hidden_size,num_layers=num_layers, dropout=dropout_p, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self,x, hidden, cell):\n",
    "        out = self.dropout(self.embedding(x))\n",
    "        \n",
    "        out, (hidden,cell) = self.lstm(out,(hidden,cell))\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden, cell\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b7e2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,encoder,decoder):\n",
    "        super(Seq2Seq,self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self,x,y,teacher_force_ratio=0.5):\n",
    "        \n",
    "        hidden,cell = self.encoder(x)\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        sentence_length = y.shape[1]\n",
    "        target_vocab_size = len(english_vocab)\n",
    "        \n",
    "        # output =  length of batch*sentence* target vocabulary size\n",
    "        output = torch.zeros(batch_size,sentence_length,target_vocab_size).to(device)\n",
    "        \n",
    "        # first token passed will be <SOS> for eng (i.e. y)\n",
    "        # y is batchsize*len\n",
    "        # decoder will take 1 word of all samples in batch at a time\n",
    "        # so decoder will batch_size * 1\n",
    "        \n",
    "        inp = y[:,0].reshape(-1,1)\n",
    "        \n",
    "        for i in range(1,y.shape[1]):\n",
    "            #print(inp.shape)\n",
    "            out,hidden,cell = self.decoder(inp,hidden,cell)\n",
    "            out =  out.reshape(batch_size,-1)\n",
    "            output[:,i,:] = out\n",
    "            \n",
    "            # out is in the shape of batch_size * vocab_size \n",
    "            #print('out',out.shape)\n",
    "            guess = out.argmax(1).reshape(-1,1)\n",
    "            \n",
    "            inp = guess if random.random()<teacher_force_ratio else y[:,i].reshape(-1,1)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81a3de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "# Model hyperparameters\n",
    "load_model = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size_encoder = len(german_vocab)\n",
    "input_size_decoder = len(english_vocab)\n",
    "output_size = len(english_vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024  # Needs to be the same for both RNN's\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f7d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccc42fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_size_encoder,encoder_embedding_size,hidden_size,num_layers,enc_dropout).to(device)\n",
    "decoder = Decoder(input_size_decoder,decoder_embedding_size,hidden_size,output_size,num_layers,dec_dropout).to(device)\n",
    "model = Seq2Seq(encoder,decoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdc193e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = english_vocab.tokens_to_bow(['<PAD>'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4def89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_model(file_name = 'data.pth'):\n",
    "    data = {\n",
    "        'input_size_encoder':input_size_encoder,\n",
    "        'input_size_decoder':input_size_decoder,\n",
    "        'output_size' : output_size,\n",
    "        'encoder_embedding_size' : encoder_embedding_size,\n",
    "        'decoder_embedding_size' : decoder_embedding_size,\n",
    "        'hidden_size'  : hidden_size,\n",
    "        'num_layers'   : num_layers,\n",
    "        'enc_dropout'  : enc_dropout,\n",
    "        'dec_dropout'  : dec_dropout,\n",
    "        'tokenizer_en' : tokenizer_en,\n",
    "        'tokenizer_de' : tokenizer_de,\n",
    "        'english_vocab': english_vocab,\n",
    "        'german_vocab' : german_vocab,\n",
    "        'encoder_sate' : encoder.state_dict(),\n",
    "        'decoder_state': decoder.state_dict(),\n",
    "        'seq2seq_state': model.state_dict(),\n",
    "    }\n",
    "    torch.save(data,file_name)\n",
    "def Save_state_dicts():\n",
    "    torch.save(encoder.state_dict(),'enc.pth')\n",
    "    torch.save(decoder.state_dict(),'dec.pth')\n",
    "    torch.save(model.state_dict(),'s2s.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ac4d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db1cd005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9907619953155518\n",
      "4.4972243309021\n",
      "3.3224780559539795\n",
      "3.1153604984283447\n",
      "2.545489549636841\n",
      "1.8848296403884888\n",
      "3.277812957763672\n",
      "1.836174726486206\n",
      "2.100801706314087\n",
      "2.7182295322418213\n",
      "2.0909359455108643\n",
      "3.1290619373321533\n",
      "2.2757534980773926\n",
      "1.7318495512008667\n",
      "2.0310328006744385\n",
      "1.7104735374450684\n",
      "1.560773491859436\n",
      "1.074495553970337\n",
      "2.125704050064087\n",
      "1.9563441276550293\n",
      "1.9879615306854248\n",
      "1.1547415256500244\n",
      "1.4417831897735596\n",
      "1.9300510883331299\n",
      "1.01298987865448\n",
      "1.0182204246520996\n",
      "1.2741928100585938\n",
      "1.151524543762207\n",
      "0.9243612885475159\n",
      "1.2822558879852295\n",
      "0.9856067299842834\n",
      "0.6004963517189026\n",
      "0.5417779088020325\n",
      "1.3924328088760376\n",
      "0.6913865804672241\n",
      "0.8250875473022461\n",
      "0.9933826327323914\n",
      "0.8478679656982422\n",
      "0.852372407913208\n",
      "1.1250052452087402\n",
      "0.8091843724250793\n",
      "0.8083226084709167\n",
      "0.7912936210632324\n",
      "0.8868674039840698\n",
      "0.8334425091743469\n",
      "0.3057456612586975\n",
      "1.2683159112930298\n",
      "0.3969021439552307\n",
      "0.680704653263092\n",
      "1.0086941719055176\n",
      "0.9130188226699829\n",
      "0.7296795845031738\n",
      "0.5330160856246948\n",
      "0.45627692341804504\n",
      "0.3278536796569824\n",
      "0.6024941802024841\n",
      "0.38747942447662354\n",
      "0.34740567207336426\n",
      "0.23816853761672974\n",
      "0.7576296925544739\n",
      "0.20972777903079987\n",
      "0.37285518646240234\n",
      "0.3578324317932129\n",
      "0.2729196548461914\n",
      "0.5835397839546204\n",
      "0.3272130489349365\n",
      "0.3831154406070709\n",
      "0.29650139808654785\n",
      "0.397132933139801\n",
      "0.47736355662345886\n",
      "0.15028925240039825\n",
      "0.35052451491355896\n",
      "0.7048043012619019\n",
      "0.36931389570236206\n",
      "0.3714281916618347\n",
      "0.3943837285041809\n",
      "0.6370837688446045\n",
      "0.2440684735774994\n",
      "0.48129960894584656\n",
      "0.2695470452308655\n",
      "0.6468870043754578\n",
      "0.44950005412101746\n",
      "0.16060106456279755\n",
      "0.1553000658750534\n",
      "0.5281938314437866\n",
      "0.335908979177475\n",
      "0.2603614032268524\n",
      "0.6312863826751709\n",
      "0.4052259624004364\n",
      "0.3528825044631958\n",
      "0.3176637589931488\n",
      "0.3633447587490082\n",
      "0.535790741443634\n",
      "0.12551173567771912\n",
      "0.22697411477565765\n",
      "0.16235539317131042\n",
      "0.14805471897125244\n",
      "0.26673653721809387\n",
      "0.09583548456430435\n",
      "0.44633162021636963\n"
     ]
    }
   ],
   "source": [
    "if(load_model):\n",
    "    encoder.load_state_dict(torch.load('enc.pth'))\n",
    "    decoder.load_state_dict(torch.load('dec.pth'))\n",
    "    model.load_state_dict(torch.load('s2s.pth'))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for de,en  in train_loader:\n",
    "        de , en = de.to(device), en.to(device)\n",
    "        out = model(de,en)\n",
    "        \n",
    "        en = en[:,1:].reshape(-1)\n",
    "        out = out[:,1:,:].reshape(-1,output_size)\n",
    "        \n",
    "        loss = criterion(out,en)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    Save_state_dicts()\n",
    "        \n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48df6daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5741b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(10000, 300)\n",
       "    (lstm): LSTM(300, 1024, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(9796, 300)\n",
       "    (lstm): LSTM(300, 1024, num_layers=2, batch_first=True, dropout=0.5)\n",
       "    (fc): Linear(in_features=1024, out_features=9796, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aa51d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(german_sentence):\n",
    "    \n",
    "    tokens = ['<SOS>'] + tokenizer_de(german_sentence) + ['<EOS>']\n",
    "    bow_ger = german_vocab.tokens_to_bow(tokens)\n",
    "    bow_ger = torch.tensor(bow_ger,dtype=torch.int64).reshape(1,-1).to(device)\n",
    "        \n",
    "    english_translation= english_vocab.tokens_to_bow(['<SOS>'])\n",
    "    eos_token = english_vocab.tokens_to_bow(['<EOS>'])[0]\n",
    "    max_len = 50\n",
    "    \n",
    "    with torch.no_grad():   \n",
    "        hidden,cell = encoder(bow_ger)\n",
    "    \n",
    "        for i in range(1,50):\n",
    "            if(english_translation[-1] == eos_token):\n",
    "                break\n",
    "            last_word = torch.tensor(english_translation[-1],dtype=torch.int64).reshape(1,1).to(device)\n",
    "        \n",
    "            predicted,hidden,cell = decoder(last_word,hidden,cell)\n",
    "        \n",
    "            english_translation.append(predicted.reshape(-1).argmax().item())\n",
    "        return  english_vocab.bow_to_tokens(english_translation[1:-1])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "df4d8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_predictions():\n",
    "    correct_eng =[]\n",
    "    predicted_eng = []\n",
    "    for german, eng in validation_data:\n",
    "        correct_eng.append(eng)\n",
    "        predicted_eng.append(' '.join(translate_sentence(german)))\n",
    "    \n",
    "   \n",
    "    return correct_eng,predicted_eng\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ff24dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct,predicted = get_validation_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5cbff134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A group of men are loading cotton onto a truck\n",
      " : group of men loading organizing a a long boat . \n",
      "\n",
      "A man sleeping in a green room on a couch.\n",
      " : a man is on a green couch in a bed . \n",
      "\n",
      "A boy wearing headphones sits on a woman's shoulders.\n",
      " : a boy boy with a face is sitting on a woman 's shoulders . \n",
      "\n",
      "Two men setting up a blue ice fishing hut on an iced over lake\n",
      " : two men are a blue on a red container on a concrete surface . \n",
      "\n",
      "A balding man wearing a red life jacket is sitting in a small boat.\n",
      " : a man with red short no no shirt sitting in a small car . \n",
      "\n",
      "A lady in a red coat, holding a bluish hand bag likely of asian descent, jumping off the ground for a snapshot.\n",
      " : a woman in a red coat holds a digital camera out of a into the plastic to another a red bucket with a far out . \n",
      "\n",
      "A brown dog is running after the black dog.\n",
      " : a brown dog runs over the and white . \n",
      "\n",
      "A young boy wearing a Giants jersey swings a baseball bat at an incoming pitch.\n",
      " : a young boy wearing a baseball hat is throwing a bat into a bat . \n",
      "\n",
      "A man in a cluttered office is using the telephone\n",
      " : a man at a train train . \n",
      "\n",
      "A smiling woman in a peach tank top stands holding a mountain bike\n",
      " : a smiling woman with a \" is holding a baby . \n",
      "\n",
      "A young child is standing alone on some jagged rocks.\n",
      " : a young child smiling along a rock face . \n",
      "\n",
      "A person on a snowmobile in mid jump.\n",
      " : person on a ski - wheeler outfit in the ocean . \n",
      "\n",
      "Three young children stand around a blue and white barrel.\n",
      " : three little children standing around a table for a \n",
      "\n",
      "A woman is sitting by her dried flower display at an outside market.\n",
      " : a woman sits on her toy toy in a car . \n",
      "\n",
      "A female playing a song on her violin.\n",
      " : a woman playing an instrument on stage . \n",
      "\n",
      "Three people on two dirt-bikes and one four-wheeler are riding through brown grass.\n",
      " : three people on horses wearing their 4 and white helmets through running through a field . \n",
      "\n",
      "A half naked man is sleeping on his chair outdoors.\n",
      " : a man sitting down on his outside . \n",
      "\n",
      "A group of people standing in front of a hut in a parking lot.\n",
      " : a group of people are standing in front of a fire on a brick road . \n",
      "\n",
      "A young woman is making rugs in the rain forest\n",
      " : a young woman is enjoying her makeup in her dryer . \n",
      "\n",
      "Three girls make faces as one takes a drink while they stand in a busy street.\n",
      " : three girls , one of pink and talking to a standing in a street . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,j  in zip(correct[:20],predicted[:20]):\n",
    "    print(i,':',j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
